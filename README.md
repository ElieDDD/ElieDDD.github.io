# ElieDDD.github.io
>Exploring Transformers, Embedding and other key aspects of Generative AI
>Computer Vision: image classification, object detection, and segmentation,  'Multimodal' zero-shot image classification. CNNs learning directly from images, pooling.
>See: https://huggingface.co/docs/transformers.js/en/index
'We find that use of model-generated content in training causes
 irreversible defects in the resulting models, where tails of the original content distribution disappear.
 We refer to this effect as model collapse1 and show that it can occur in Variational Autoencoders,
 Gaussian Mixture Models and LLMs. We build theoretical intuition behind the phenomenon and
 portray its ubiquity amongst all learned generative models'
>Shumailov, I., Shumaylov, Z., Zhao, Y., Gal, Y., Papernot, N., & Anderson, R. (2023). The Curse of Recursion: Training on Generated Data Makes Models Forget. ArXiv, abs/2305.17493.
>
>CNNs 'You train a CNN to do image analysis tasks, including scene classification, object detection and segmentation, and image processing. In order to understand how CNNs work, we'll cover three key concepts: local receptive fields, shared weights and biases, and activation and pooling.' https://uk.mathworks.com/

<b>'Unnatural learning procesess' </b>
Ideas: 'Feeding ordered data to a model sequentially can lead to an unnatural, unbalanced learning process.' Nguyen

'Augmentation helps generate more unbiased data' - such as flipping and rotating synthetic images and more to prevent <b> overfit </b>, look at Data Augmentation, see:https://github.com/aleju/imgaug


